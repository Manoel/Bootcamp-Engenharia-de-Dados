# Plano de ensino do Módulo 4
## Pipelines de Dados<br></br>


## Capítulo 1. Visual geral do pipeline de ciência de dados<br></br>

1. Visual geral do pipeline de ciência de dados: 
    * coleta 
    * preparação 
    * armazenamento 
    * processamento/análise 
    * visualização 
    * implantação<br></br>

 
## Capítulo 2. Extração de dados - ENADE - INEP - Ministério da Educação<br></br>

2.1 Extração automatizada dos dados

2.2 Transformação de dados - Parte 1

2.3 Transformação de dados - Parte 2<br></br>

 
## Capítulo 3. Extração de dados - Prática - Twitter API<br></br>

3.1 Configurando uma conta de DEV no Twtiter

3.2 Criando um app e pegando as chaves de acesso

3.3 Construindo um crawler para fazer streaming de tweets<br></br>

 
## Capítulo 4. Transformação de dados - Prática - Organização e Tratamento dos dados<br></br>

4.1 Entendendo o formato do tweet - JSON

4.2 Limpeza e organização dos dados do Twitter - Parte 1

4.3 Limpeza e organização dos dados do Twitter - Parte 2

4.4 Ingestão de dados do Twitter em tabela relacional<br></br>

 
## Trabalho Prático<br></br> 

 
## Capítulo 5. Visão geral de soluções para extração, ingestão, transformação, armazenamento e análise de dados - Data Flow<br></br>

5.1 Introdução

5.2. Soluções para “Drag and Drop”

5.2.1 Pentaho

5.2.2 Nifi

5.3 Soluções com código

5.3.1 AirFlow

5.3.2 KubeFlow

5.3.3 Prefect<br></br>

 
## Capítulo 6. Data Flow na prática - AirFlow<br></br>

6.1 Instalação do AirFlow

6.2 AirFlow rodando na nuvem

6.3 Tasks do AirFlow

6.4 Programando execuções do Pipeline 

6.5 Condicionais

6.6 Paralelismos 

6.7 Integrações para entrega<br></br>

 
## Capítulo 7. Data Flow na prática - Prefect

7.1 Configuração do ambiente Prefect na nuvem

7.2 Tasks do Prefect

7.3 Programando execuções e analisando o dashboard

7.4 Integrações para entrega<br></br>

 
## Capítulo 8. Pipelines de Dados near real time com Kafka<br></br> 

8.1 Configuração do ambiente usando docker-compose

8.2 Implementando o pipeline<br></br>